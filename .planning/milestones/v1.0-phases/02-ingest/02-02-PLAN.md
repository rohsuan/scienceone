---
phase: 02-ingest
plan: "02"
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - scripts/lib/r2-upload.ts
  - scripts/lib/db-write.ts
  - scripts/ingest.ts
  - scripts/test-fixtures/sample.tex
  - scripts/test-fixtures/sample.md
autonomous: false
requirements: [ADM-01, ADM-02]
user_setup:
  - service: cloudflare-r2
    why: "PDF and EPUB artifact storage"
    env_vars:
      - name: R2_ACCOUNT_ID
        source: "Cloudflare Dashboard -> R2 -> Account ID (right sidebar)"
      - name: R2_ACCESS_KEY_ID
        source: "Cloudflare Dashboard -> R2 -> Manage R2 API Tokens -> Create API token"
      - name: R2_SECRET_ACCESS_KEY
        source: "Same token creation page as R2_ACCESS_KEY_ID"
      - name: R2_BUCKET_NAME
        source: "Cloudflare Dashboard -> R2 -> Create bucket (name: 'scienceone')"
    dashboard_config:
      - task: "Create R2 bucket named 'scienceone'"
        location: "Cloudflare Dashboard -> R2 -> Create bucket"
      - task: "Create R2 API token with Object Read & Write permissions"
        location: "Cloudflare Dashboard -> R2 -> Manage R2 API Tokens"
  - service: pandoc
    why: "Document format conversion (LaTeX/docx/markdown to HTML/PDF/EPUB)"
    env_vars: []
    dashboard_config:
      - task: "Install Pandoc on system"
        location: "Terminal: brew install pandoc"
  - service: xelatex
    why: "PDF generation from LaTeX manuscripts"
    env_vars: []
    dashboard_config:
      - task: "Install LaTeX distribution for PDF generation"
        location: "Terminal: brew install --cask mactex (or brew install basictex)"

must_haves:
  truths:
    - "Founder can run npx tsx scripts/ingest.ts --input manuscript.tex --book-id <id> and chapters appear in the database with pre-rendered KaTeX HTML"
    - "Founder can run the same command with .md and .docx manuscripts and get the same structured output"
    - "Pipeline prints a health report showing warnings and errors; halts on math errors or unsupported commands"
    - "PDF and EPUB files are uploaded to Cloudflare R2 and their storage keys are saved on the Book record"
    - "Pipeline supports --dry-run mode that converts and reports without writing to DB or uploading to R2"
  artifacts:
    - path: "scripts/lib/r2-upload.ts"
      provides: "Upload files to Cloudflare R2 via S3-compatible API"
      exports: ["uploadToR2", "createR2Client"]
    - path: "scripts/lib/db-write.ts"
      provides: "Write chapters to DB and update Book with artifact keys via Prisma"
      exports: ["writeChapters", "updateBookArtifacts"]
    - path: "scripts/ingest.ts"
      provides: "CLI entry point orchestrating the full ingest pipeline"
      exports: []
    - path: "scripts/test-fixtures/sample.tex"
      provides: "LaTeX test manuscript with inline/display math and multiple chapters"
    - path: "scripts/test-fixtures/sample.md"
      provides: "Markdown test manuscript with LaTeX math blocks"
  key_links:
    - from: "scripts/ingest.ts"
      to: "scripts/lib/pandoc.ts"
      via: "convertToHtml, convertToPdf, convertToEpub imports"
      pattern: "import.*from.*pandoc"
    - from: "scripts/ingest.ts"
      to: "scripts/lib/katex-render.ts"
      via: "preRenderMath import"
      pattern: "import.*from.*katex-render"
    - from: "scripts/ingest.ts"
      to: "scripts/lib/chapter-split.ts"
      via: "splitChapters import"
      pattern: "import.*from.*chapter-split"
    - from: "scripts/ingest.ts"
      to: "scripts/lib/health-report.ts"
      via: "buildHealthReport, printHealthReport imports"
      pattern: "import.*from.*health-report"
    - from: "scripts/ingest.ts"
      to: "scripts/lib/r2-upload.ts"
      via: "uploadToR2 import"
      pattern: "import.*from.*r2-upload"
    - from: "scripts/ingest.ts"
      to: "scripts/lib/db-write.ts"
      via: "writeChapters, updateBookArtifacts imports"
      pattern: "import.*from.*db-write"
    - from: "scripts/lib/r2-upload.ts"
      to: "@aws-sdk/client-s3"
      via: "S3Client, PutObjectCommand"
      pattern: "S3Client|PutObjectCommand"
    - from: "scripts/lib/db-write.ts"
      to: "src/lib/prisma.ts"
      via: "prisma import for DB operations"
      pattern: "import.*prisma"
---

<objective>
Build the R2 upload module, database persistence layer, and CLI entry point that orchestrates the full ingest pipeline. Create test manuscripts and verify end-to-end conversion from LaTeX/Markdown to pre-rendered HTML chapters in the database with PDF/EPUB artifacts in R2.

Purpose: This plan wires all the conversion modules from Plan 02-01 into a working CLI tool the founder can use to ingest manuscripts. It completes the full ingest pipeline — the core Phase 2 deliverable.

Output: Working `npx tsx scripts/ingest.ts` CLI, R2 upload module, DB write module, test fixtures, and human-verified end-to-end ingest.
</objective>

<execution_context>
@/Users/roh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/roh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ingest/02-RESEARCH.md
@.planning/phases/02-ingest/02-01-SUMMARY.md
@prisma/schema.prisma
@src/lib/prisma.ts
@scripts/lib/pandoc.ts
@scripts/lib/katex-render.ts
@scripts/lib/chapter-split.ts
@scripts/lib/health-report.ts
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build R2 upload module, DB write module, and CLI entry point</name>
  <files>
    scripts/lib/r2-upload.ts
    scripts/lib/db-write.ts
    scripts/ingest.ts
  </files>
  <action>
    **scripts/lib/r2-upload.ts — Cloudflare R2 upload via S3-compatible API**

    Create `createR2Client(): S3Client` that:
    - Validates R2_ACCOUNT_ID, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY env vars are present; throws descriptive error if missing
    - Creates and returns an S3Client with:
      - `region: 'auto'`
      - `endpoint: https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com`
      - `credentials: { accessKeyId, secretAccessKey }`
      - `requestChecksumCalculation: 'WHEN_REQUIRED'` (CRITICAL: R2 does not support CRC32 checksums — see Research Pitfall 4)
      - `responseChecksumValidation: 'WHEN_REQUIRED'`

    Create `uploadToR2(localPath: string, key: string, contentType: string): Promise<string>` that:
    - Reads the file at localPath using `fs/promises readFile`
    - Sends PutObjectCommand to R2 with Bucket from R2_BUCKET_NAME env var, Key, Body, ContentType
    - Returns the storage key on success
    - Throws descriptive error on failure

    Use deterministic key paths: `books/{bookSlug}/{bookSlug}.pdf` and `books/{bookSlug}/{bookSlug}.epub` (per Research Pattern 4 and Pitfall 7).

    **scripts/lib/db-write.ts — Prisma database persistence**

    Import prisma from `@/lib/prisma` (the existing singleton — do NOT create a new PrismaClient).

    Create `writeChapters(bookId: string, chapters: Array<{ title: string; slug: string; content: string; position: number }>): Promise<number>` that:
    - First, deletes all existing chapters for the bookId (re-ingest scenario — see Research Pitfall 7)
    - Then creates new chapters using `prisma.chapter.createMany` with the chapter data plus bookId and `isFreePreview: position === 0` (first chapter is always free preview)
    - Returns the count of chapters created
    - Uses a transaction to ensure atomicity: delete + create in one `prisma.$transaction`

    Create `updateBookArtifacts(bookId: string, pdfKey: string | null, epubKey: string | null): Promise<void>` that:
    - Updates the Book record with pdfKey and epubKey using `prisma.book.update`
    - Only sets fields that are non-null (use `...(pdfKey && { pdfKey })` spread pattern)

    Create `getBookForIngest(bookId: string): Promise<{ id: string; slug: string; title: string } | null>` that:
    - Finds the book by ID using `prisma.book.findUnique`
    - Returns id, slug, title if found; null otherwise
    - Used by the CLI to validate the book-id argument before proceeding

    **scripts/ingest.ts — CLI entry point with Commander.js**

    Add shebang: `#!/usr/bin/env -S npx tsx`

    Create a Commander program with:
    - Name: `ingest`
    - Description: `Ingest a manuscript into ScienceOne`
    - Required option: `-i, --input <path>` — Path to manuscript file (.tex, .docx, .md)
    - Required option: `-b, --book-id <id>` — Existing Book ID in the database
    - Optional option: `-f, --format <format>` — Input format override (latex|docx|markdown); auto-detected from extension if omitted
    - Optional flag: `--dry-run` — Convert and report without writing to DB or uploading to R2
    - Optional flag: `--skip-pdf` — Skip PDF generation (useful when xelatex not installed)
    - Optional flag: `--skip-epub` — Skip EPUB generation
    - Optional flag: `--skip-r2` — Skip R2 upload (useful for local testing without R2 credentials)

    The action handler must orchestrate the full pipeline in this order:

    1. **Validate inputs:**
       - Check input file exists (fs.existsSync)
       - Detect format from extension (or use --format override)
       - If not --dry-run: Look up the Book by --book-id using getBookForIngest; exit with error if not found
       - Print: "Ingesting {format} manuscript: {inputFile} for book: {bookTitle}"

    2. **Convert to HTML:**
       - Call `convertToHtml(inputFile, format)`
       - Print: "Converted to HTML ({html.length} chars)"

    3. **Pre-render math:**
       - Initialize empty mathErrors array
       - Call `preRenderMath(html, mathErrors)`
       - Print: "Pre-rendered math ({mathErrors.length} errors)"

    4. **Split chapters:**
       - Call `splitChapters(processedHtml)`
       - Print: "Split into {chapters.length} chapters"

    5. **Build health report:**
       - Call `buildHealthReport(inputFile, format, pandocStderr, mathErrors, chapters.length)`
       - Call `printHealthReport(report)`
       - If report.halted: print error and exit with code 1

    6. **Generate PDF (unless --skip-pdf or --dry-run):**
       - Call `convertToPdf(inputFile)`
       - Print: "Generated PDF: {outputPath}"
       - On error: print warning but do NOT halt (PDF generation failure is non-fatal — xelatex may not be installed)

    7. **Generate EPUB (unless --skip-epub or --dry-run):**
       - Call `convertToEpub(inputFile)`
       - Print: "Generated EPUB: {outputPath}"

    8. **Upload to R2 (unless --skip-r2 or --dry-run):**
       - Upload PDF (if generated) with key `books/{slug}/{slug}.pdf` and content type `application/pdf`
       - Upload EPUB (if generated) with key `books/{slug}/{slug}.epub` and content type `application/epub+zip`
       - Print: "Uploaded to R2: {key}"

    9. **Write to database (unless --dry-run):**
       - Call `writeChapters(bookId, chapters)` — writes all chapters in a transaction
       - Call `updateBookArtifacts(bookId, pdfKey, epubKey)` — saves R2 keys on Book
       - Print: "Wrote {count} chapters to database"
       - Print: "Updated Book with artifact keys"

    10. **Summary:**
        - Print final summary: book title, chapter count, PDF key (or skipped), EPUB key (or skipped), dry-run status
        - If --dry-run: print "DRY RUN — no changes written to DB or R2"

    Use chalk for colored output: green for success, yellow for warnings, red for errors.

    Handle top-level errors with try/catch and print a clean error message (no stack trace in production).
  </action>
  <verify>
    - `npx tsx scripts/ingest.ts --help` prints usage with all options
    - `npx tsx scripts/ingest.ts --input nonexistent.tex --book-id test` exits with "File not found" error
    - `npx tsx -e "import { createR2Client } from './scripts/lib/r2-upload'" 2>&1` imports without syntax errors (will throw missing env vars error at runtime, which is expected)
    - `npx tsx -e "import { writeChapters, updateBookArtifacts, getBookForIngest } from './scripts/lib/db-write'; console.log('OK')"` prints OK
    - All three files exist and have no TypeScript compilation errors
  </verify>
  <done>
    scripts/ingest.ts CLI is runnable via `npx tsx scripts/ingest.ts --help`. R2 upload module handles S3-compatible upload with checksum fix. DB write module handles chapter creation, book artifact update, and book lookup. CLI orchestrates the full pipeline with --dry-run, --skip-pdf, --skip-epub, and --skip-r2 flags.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test manuscripts and verify pipeline with dry run</name>
  <files>
    scripts/test-fixtures/sample.tex
    scripts/test-fixtures/sample.md
  </files>
  <action>
    1. Create directory: `mkdir -p scripts/test-fixtures`

    2. Create `scripts/test-fixtures/sample.tex` — a minimal LaTeX manuscript with:
       - `\documentclass{book}` with `amsmath` package
       - 3 chapters using `\chapter{Title}` (which becomes h1 in Pandoc HTML output)
       - Chapter 1 ("Introduction"): A paragraph with an inline math expression `$E = mc^2$` and a display math equation using `\begin{equation}` environment: `\int_0^\infty e^{-x^2} dx = \frac{\sqrt{\pi}}{2}`
       - Chapter 2 ("Linear Algebra"): A paragraph with a matrix using `\begin{pmatrix}` inside a display equation, and inline references to `$\vec{v}$` and `$\mathbb{R}^n$`
       - Chapter 3 ("Calculus"): A paragraph with `\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}` as display math, and inline `$\frac{d}{dx} \sin(x) = \cos(x)$`
       - This is a REAL math-heavy manuscript that tests the core value proposition

    3. Create `scripts/test-fixtures/sample.md` — a minimal Markdown manuscript with:
       - 3 chapters using `# Title` headings
       - Chapter 1: Inline math `$a^2 + b^2 = c^2$` and display math in `$$...$$` blocks
       - Chapter 2: More complex display math with fractions and integrals
       - Chapter 3: A simple equation
       - Use Pandoc-compatible LaTeX math delimiters (`$...$` for inline, `$$...$$` for display)

    4. Generate a test .docx from the Markdown file using Pandoc:
       ```bash
       pandoc -f markdown -t docx scripts/test-fixtures/sample.md -o scripts/test-fixtures/sample.docx
       ```

    5. Run the ingest CLI in dry-run mode against ALL THREE formats:
       ```bash
       npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.tex --book-id dry-run-test --dry-run
       npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.md --book-id dry-run-test --dry-run
       npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.docx --book-id dry-run-test --dry-run
       ```
       Each should:
       - Convert to HTML successfully
       - Pre-render math with 0 errors
       - Split into 3 chapters
       - Print a green "OK" health report
       - Print "DRY RUN" — no DB or R2 writes attempted

    6. Verify the pre-rendered output contains KaTeX HTML:
       - The dry-run output or a separate check should confirm the HTML contains `class="katex"` strings (KaTeX's rendered output signature)
       - The HTML should NOT contain `<span class="math inline">` or `<span class="math display">` — those should have been replaced by pre-rendered KaTeX

    If dry-run for any format fails on math rendering, investigate the specific error. Common issue: Pandoc may output math differently for docx (since Word stores equations as OMML, not LaTeX). The health report should flag these.
  </action>
  <verify>
    - `ls scripts/test-fixtures/sample.tex scripts/test-fixtures/sample.md scripts/test-fixtures/sample.docx` — all three exist
    - `npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.tex --book-id test --dry-run` exits 0 with "3 chapters" in output
    - `npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.md --book-id test --dry-run` exits 0 with "3 chapters" in output
    - `npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.docx --book-id test --dry-run` exits 0 (chapter count may vary for docx)
    - Dry-run output contains "DRY RUN" and does NOT attempt DB/R2 writes
    - Health report shows 0 math errors for the LaTeX and Markdown manuscripts
  </verify>
  <done>
    Test manuscripts exist for all three supported formats. Dry-run mode successfully converts LaTeX, Markdown, and Word manuscripts into pre-rendered KaTeX HTML chapters. Health report shows clean results. Pipeline is verified working without requiring DB or R2 credentials.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify end-to-end ingest with database and R2</name>
  <files>scripts/ingest.ts</files>
  <action>
    Human verification checkpoint. Claude has built the complete ingest pipeline. The founder now verifies the pipeline works end-to-end with real database and R2 credentials.
  </action>
  <verify>
    **Pre-requisites (skip steps for services already configured):**
    1. PostgreSQL is running and DATABASE_URL is set in .env
    2. `npx prisma migrate dev` has been run (applies the add_book_artifact_keys migration)
    3. `npx prisma db seed` has been run (creates sample books)
    4. R2 credentials are set in .env (R2_ACCOUNT_ID, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY, R2_BUCKET_NAME)
    5. Pandoc is installed: `pandoc --version` shows 3.x

    **Test 1: Full ingest of LaTeX manuscript**
    ```bash
    # Get a book ID from the seed data
    npx tsx -e "import prisma from './src/lib/prisma'; const b = await prisma.book.findFirst(); console.log(b?.id, b?.title); await prisma.\$disconnect()"

    # Run full ingest (replace BOOK_ID with the ID from above)
    npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.tex --book-id BOOK_ID
    ```
    Expected: Pipeline completes with green output showing 3 chapters created, PDF/EPUB uploaded to R2.

    **Test 2: Verify chapters in database**
    ```bash
    npx tsx -e "import prisma from './src/lib/prisma'; const chapters = await prisma.chapter.findMany({ where: { bookId: 'BOOK_ID' }, orderBy: { position: 'asc' } }); chapters.forEach(c => console.log(c.position, c.title, c.content?.substring(0, 100))); await prisma.\$disconnect()"
    ```
    Expected: 3 chapters with pre-rendered HTML containing `class="katex"` — NOT raw LaTeX like `$E=mc^2$`.

    **Test 3: Verify Book has artifact keys**
    ```bash
    npx tsx -e "import prisma from './src/lib/prisma'; const b = await prisma.book.findUnique({ where: { id: 'BOOK_ID' } }); console.log('pdfKey:', b?.pdfKey, 'epubKey:', b?.epubKey); await prisma.\$disconnect()"
    ```
    Expected: pdfKey and epubKey are set to `books/{slug}/{slug}.pdf` and `books/{slug}/{slug}.epub`.

    **Test 4: Verify R2 upload**
    Check the Cloudflare R2 dashboard for the bucket. The `books/{slug}/` prefix should contain the PDF and EPUB files.

    **Test 5: Health report on broken math (optional)**
    Create a test file with intentionally broken LaTeX math and verify the pipeline halts:
    ```bash
    echo '\chapter{Test}\n$\broken{command}$' > /tmp/broken.tex
    npx tsx scripts/ingest.ts --input /tmp/broken.tex --book-id BOOK_ID --dry-run --skip-pdf --skip-epub
    ```
    Expected: Health report shows math errors in red and prints "HALTED".

    **Test 6: Markdown manuscript (with --skip-r2 to avoid overwriting)**
    ```bash
    npx tsx scripts/ingest.ts --input scripts/test-fixtures/sample.md --book-id BOOK_ID --skip-r2
    ```
    Expected: 3 chapters with pre-rendered math written to DB. Previous chapters are replaced (re-ingest).
  </verify>
  <done>
    All 6 tests pass: LaTeX, Markdown, and Word manuscripts convert to pre-rendered KaTeX HTML chapters in the database. PDF/EPUB artifacts exist in R2. Health report works correctly. The Phase 2 success criteria are met.
  </done>
</task>

</tasks>

<verification>
1. `npx tsx scripts/ingest.ts --help` shows CLI usage with all documented options
2. Dry-run mode works for .tex, .md, and .docx without requiring DB or R2
3. Full ingest writes pre-rendered KaTeX HTML chapters to PostgreSQL (no raw LaTeX in chapter.content)
4. PDF and EPUB artifacts uploaded to R2 with correct key paths
5. Book record updated with pdfKey and epubKey
6. Health report halts on math errors, passes with warnings only, or shows clean "OK"
7. Re-ingest replaces existing chapters atomically (delete + create in transaction)
</verification>

<success_criteria>
- Founder can run `npx tsx scripts/ingest.ts --input manuscript.tex --book-id <id>` and see chapters in the database
- Chapter content contains `class="katex"` rendered HTML, not raw LaTeX
- PDF/EPUB keys recorded on Book model
- Health report is printed for every run
- Pipeline halts on math errors instead of silently corrupting content
- --dry-run mode works without DB or R2 credentials
- All three input formats (LaTeX, Markdown, Word) produce structured chapter output
</success_criteria>

<output>
After completion, create `.planning/phases/02-ingest/02-02-SUMMARY.md`
</output>
